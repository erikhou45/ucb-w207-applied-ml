{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "import theano \n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "print(theano.config.device) # We're using CPUs (for now)\n",
    "print(theano.config.floatX) # Should be 64 bit for CPUs\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forest-cover-type-prediction/train.csv', 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "\n",
    "my_data = np.genfromtxt('forest-cover-type-prediction/train.csv', delimiter=',')\n",
    "data = my_data[1:, 1:my_data.shape[1]-1]  # avoid getting headers and ID column\n",
    "labels = my_data[1:,-1]\n",
    "\n",
    "# shuffle the training data\n",
    "np.random.seed(0)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(data.shape[0]))\n",
    "\n",
    "shuffled_data = data[shuffle]\n",
    "shuffled_labels = labels[shuffle]\n",
    "shuffled_labels = shuffled_labels - 1\n",
    "\n",
    "# split the data to 60% train, 20% dev and 20% test\n",
    "num_train = int(shuffled_data.shape[0]*0.7)\n",
    "num_dev = int(shuffled_data.shape[0]*1)\n",
    "\n",
    "train_data, train_labels = shuffled_data[:num_train], shuffled_labels[:num_train]\n",
    "test_data, test_labels = shuffled_data[num_train:num_dev], shuffled_labels[num_train:num_dev]\n",
    "# test_data, test_labels = shuffled_data[num_dev:], shuffled_labels[num_dev:]\n",
    "\n",
    "numFeatures = train_data[1].size\n",
    "numTrainExamples = train_data.shape[0]\n",
    "numTestExamples = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes =  7\n"
     ]
    }
   ],
   "source": [
    "def binarizeY(data):\n",
    "    binarized_data = np.zeros((data.size,7))\n",
    "    for j in range(0,data.size):\n",
    "        feature = data[j:j+1]\n",
    "        i = feature.astype(np.int64) \n",
    "        binarized_data[j,i]=1\n",
    "    return binarized_data\n",
    "train_labels_b = binarizeY(train_labels)\n",
    "test_labels_b = binarizeY(test_labels)\n",
    "numClasses = train_labels_b[1].size\n",
    "print('Classes = ', numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time =  0.01576972007751465\n",
      "Accuracy =  0.6455026455026455\n",
      "Prediction time =  0.22156691551208496\n"
     ]
    }
   ],
   "source": [
    "numExamples = 1000\n",
    "neighbors = 1\n",
    "knn = KNeighborsClassifier(neighbors)\n",
    "# we'll be waiting quite a while if we use 60K examples, so let's cut it down.  You may want to run the full 60K on your own later to see what the accuracy is.\n",
    "mini_train_data, mini_train_labels = train_data[:numExamples], train_labels[:numExamples] \n",
    "start_time = time.time()\n",
    "knn.fit(mini_train_data, mini_train_labels)\n",
    "print('Train time = ', time.time() - start_time)\n",
    "start_time = time.time()\n",
    "accuracy = knn.score(test_data, test_labels)\n",
    "print('Accuracy = ', accuracy)\n",
    "print('Prediction time = ', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now that we have a simple baseline, let's start working in Theano.  Before we jump to multi-layer neural networks though, let's train a logistic regression model to make certain we're using Theano correctly. \n",
    "\n",
    "Recall from Josh's regression lecture the four key components: (1) parameters, (2) model, (3) cost function, and (4) objective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) Parameters \n",
    "# Initialize the weights to small, but non-zero, values.\n",
    "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two notes relevant at this point:\n",
    "\n",
    "First, logistic regression can be thought of as a neural network with no hidden layers. The output values are just the dot product of the inputs and the edge weights.\n",
    "\n",
    "Second, we have 10 classes. We can either train separate one vs all classifiers using sigmoid activation, which would be a hassle, or we can use the softmax activation, which is essentially a multi-class version of sigmoid. We'll use Theano's built-in implementation of softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) Model\n",
    "# Theano objects accessed with standard Python variables\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "y_hat = model(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use cross-entropy as a cost function.  Cross entropy only considers the error between the true class and the prediction, and not the errors for the false classes.  This tends to cause the network to converge faster.  We'll use Theano's built-in cross entropy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) Cost function\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is minimize the cost, and to do that we'll use batch gradient descent.\n",
    "\n",
    "Exercise: What are the differences between batch, stochastic, and mini-batch gradient descent?  What are the implications of each for working on large datasets?\n",
    "\n",
    "We'll use Theano's built-in gradient function.  Exercise: Do you recall from Josh's lecture what the gradient is for beta in logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.01})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.01})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.01})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.01})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.01})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n",
      "ERROR (theano.gof.opt): Optimization failure due to: constant_folding\n",
      "ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-1.0})\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/opt.py\", line 2034, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/tensor/opt.py\", line 6516, in constant_folding\n",
      "    no_recycling=[], impl=impl)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 955, in make_thunk\n",
      "    no_recycling)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\", line 858, in make_c_thunk\n",
      "    output_storage=node_output_storage)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1217, in make_thunk\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1157, in __compile__\n",
      "    keep_lock=keep_lock)\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1609, in cthunk_factory\n",
      "    key = self.cmodule_key()\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1300, in cmodule_key\n",
      "    c_compiler=self.c_compiler(),\n",
      "  File \"/Users/erikhou/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\", line 1379, in cmodule_key_\n",
      "    np.core.multiarray._get_ndarray_c_version())\n",
      "AttributeError: module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "('The following error happened while compiling the node', Dot22(<TensorType(float64, matrix)>, <TensorType(float64, matrix)>), '\\n', \"module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-90a3c2bf67f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# computes cost, then runs update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select largest probability as prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                   name=name)\n\u001b[1;32m   1840\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchange_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_test_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1842\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[1;32m   1713\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[0;32m-> 1715\u001b[0;31m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[1;32m   1716\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m    697\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[1;32m    698\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/vm.py\u001b[0m in \u001b[0;36mmake_all\u001b[0;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[1;32m   1089\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m                                                  \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m                                                  impl=impl))\n\u001b[0m\u001b[1;32m   1092\u001b[0m                 \u001b[0mlinker_make_thunk_time\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthunk_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lazy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling, impl)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[0;32m--> 955\u001b[0;31m                                          no_recycling)\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0;31m# We requested the c code, so don't catch the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[0;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[0;32m--> 858\u001b[0;31m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[1;32m    859\u001b[0m         \u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mmake_thunk\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1215\u001b[0m         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[1;32m   1216\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36m__compile__\u001b[0;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                                             \u001b[0moutput_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                                             \u001b[0mstorage_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                                             keep_lock=keep_lock)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         return (thunk,\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcthunk_factory\u001b[0;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \"\"\"\n\u001b[1;32m   1608\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1609\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1610\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcmodule_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                  \u001b[0mlibraries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibraries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                  \u001b[0mheader_dirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                  \u001b[0mc_compiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_compiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m                                  )\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/theano/gof/cc.py\u001b[0m in \u001b[0;36mcmodule_key_\u001b[0;34m(self, fgraph, no_recycling, compile_args, libraries, header_dirs, insert_config_hash, c_compiler)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         \u001b[0;31m# DynamicModule always add the include <numpy/arrayobject.h>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         sig.append('NPY_ABI_VERSION=0x%X' %\n\u001b[0;32m-> 1379\u001b[0;31m                    np.core.multiarray._get_ndarray_c_version())\n\u001b[0m\u001b[1;32m   1380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mc_compiler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c_compiler_str='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_compiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: ('The following error happened while compiling the node', Dot22(<TensorType(float64, matrix)>, <TensorType(float64, matrix)>), '\\n', \"module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\")"
     ]
    }
   ],
   "source": [
    "## (4) Objective (and solver)\n",
    "\n",
    "alpha = 0.01\n",
    "gradient = T.grad(cost=cost, wrt=w) \n",
    "update = [[w, w - gradient * alpha]] \n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) # computes cost, then runs update\n",
    "y_pred = T.argmax(y_hat, axis=1) # select largest probability as prediction\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "def gradientDescent(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    for i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        cost = train(train_data[0:len(train_data)], train_labels_b[0:len(train_data)])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('accuracy = ', (i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = ', trainTime)\n",
    "\n",
    "gradientDescent(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:  What do you expect to happen if we convert batch gradient descent to stochastic gradient descent?  Why?\n",
    "\n",
    "Let's try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  (1, 0.841)\n",
      "accuracy =  (2, 0.8665)\n",
      "accuracy =  (3, 0.872)\n",
      "accuracy =  (4, 0.8755)\n",
      "accuracy =  (5, 0.8775)\n",
      "accuracy =  (6, 0.8775)\n",
      "accuracy =  (7, 0.878)\n",
      "accuracy =  (8, 0.8795)\n",
      "accuracy =  (9, 0.88)\n",
      "accuracy =  (10, 0.879)\n",
      "accuracy =  (11, 0.88)\n",
      "accuracy =  (12, 0.8815)\n",
      "accuracy =  (13, 0.881)\n",
      "accuracy =  (14, 0.8795)\n",
      "accuracy =  (15, 0.8795)\n",
      "accuracy =  (16, 0.879)\n",
      "accuracy =  (17, 0.8795)\n",
      "accuracy =  (18, 0.8795)\n",
      "accuracy =  (19, 0.879)\n",
      "accuracy =  (20, 0.879)\n",
      "accuracy =  (21, 0.8795)\n",
      "accuracy =  (22, 0.879)\n",
      "accuracy =  (23, 0.879)\n",
      "accuracy =  (24, 0.8785)\n",
      "accuracy =  (25, 0.88)\n",
      "accuracy =  (26, 0.8795)\n",
      "accuracy =  (27, 0.8795)\n",
      "accuracy =  (28, 0.88)\n",
      "accuracy =  (29, 0.88)\n",
      "accuracy =  (30, 0.8805)\n",
      "accuracy =  (31, 0.881)\n",
      "accuracy =  (32, 0.8805)\n",
      "accuracy =  (33, 0.88)\n",
      "accuracy =  (34, 0.8795)\n",
      "accuracy =  (35, 0.8785)\n",
      "accuracy =  (36, 0.8785)\n",
      "accuracy =  (37, 0.8795)\n",
      "accuracy =  (38, 0.879)\n",
      "accuracy =  (39, 0.879)\n",
      "accuracy =  (40, 0.879)\n",
      "accuracy =  (41, 0.8795)\n",
      "accuracy =  (42, 0.8795)\n",
      "accuracy =  (43, 0.879)\n",
      "accuracy =  (44, 0.8795)\n",
      "accuracy =  (45, 0.879)\n",
      "accuracy =  (46, 0.879)\n",
      "accuracy =  (47, 0.8795)\n",
      "accuracy =  (48, 0.879)\n",
      "accuracy =  (49, 0.8785)\n",
      "accuracy =  (50, 0.8785)\n",
      "train time =  64.98834919929504\n",
      "predict time =  0.0011920928955078125\n"
     ]
    }
   ],
   "source": [
    "## (1) Parameters\n",
    "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "y_hat = model(X, w)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "## (4) Objective\n",
    "alpha = 0.01\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * alpha]] \n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) \n",
    "y_pred = T.argmax(y_hat, axis=1) \n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):       \n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('accuracy = ', (i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = ', trainTime)\n",
    "    \n",
    "gradientDescentStochastic(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: What do you expect to happen if you switch the batch size to be great than 1 (i.e. mini-batch)?  Why?\n",
    "\n",
    "Try it for a few values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  (1, 0.788)\n",
      "accuracy =  (2, 0.8245)\n",
      "accuracy =  (3, 0.8395)\n",
      "accuracy =  (4, 0.851)\n",
      "accuracy =  (5, 0.8565)\n",
      "accuracy =  (6, 0.861)\n",
      "accuracy =  (7, 0.865)\n",
      "accuracy =  (8, 0.867)\n",
      "accuracy =  (9, 0.8685)\n",
      "accuracy =  (10, 0.869)\n",
      "accuracy =  (11, 0.873)\n",
      "accuracy =  (12, 0.875)\n",
      "accuracy =  (13, 0.8755)\n",
      "accuracy =  (14, 0.876)\n",
      "accuracy =  (15, 0.8775)\n",
      "accuracy =  (16, 0.8765)\n",
      "accuracy =  (17, 0.8785)\n",
      "accuracy =  (18, 0.88)\n",
      "accuracy =  (19, 0.88)\n",
      "accuracy =  (20, 0.88)\n",
      "accuracy =  (21, 0.8805)\n",
      "accuracy =  (22, 0.881)\n",
      "accuracy =  (23, 0.8805)\n",
      "accuracy =  (24, 0.881)\n",
      "accuracy =  (25, 0.882)\n",
      "accuracy =  (26, 0.8825)\n",
      "accuracy =  (27, 0.8825)\n",
      "accuracy =  (28, 0.8835)\n",
      "accuracy =  (29, 0.8835)\n",
      "accuracy =  (30, 0.883)\n",
      "accuracy =  (31, 0.8825)\n",
      "accuracy =  (32, 0.883)\n",
      "accuracy =  (33, 0.883)\n",
      "accuracy =  (34, 0.883)\n",
      "accuracy =  (35, 0.8825)\n",
      "accuracy =  (36, 0.882)\n",
      "accuracy =  (37, 0.882)\n",
      "accuracy =  (38, 0.882)\n",
      "accuracy =  (39, 0.883)\n",
      "accuracy =  (40, 0.8835)\n",
      "accuracy =  (41, 0.8835)\n",
      "accuracy =  (42, 0.8835)\n",
      "accuracy =  (43, 0.883)\n",
      "accuracy =  (44, 0.8825)\n",
      "accuracy =  (45, 0.8825)\n",
      "accuracy =  (46, 0.883)\n",
      "accuracy =  (47, 0.8835)\n",
      "accuracy =  (48, 0.883)\n",
      "accuracy =  (49, 0.8835)\n",
      "accuracy =  (50, 0.8835)\n",
      "train time =  34.31850242614746\n",
      "predict time =  0.0024178028106689453\n"
     ]
    }
   ],
   "source": [
    "## (1) Parameters\n",
    "w = theano.shared(np.asarray((np.random.randn(*(numFeatures, numClasses))*.01)))\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "y_hat = model(X, w)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "## (4) Objective\n",
    "alpha = 0.01\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * alpha]] \n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True) \n",
    "y_pred = T.argmax(y_hat, axis=1) \n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 10 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):       \n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('accuracy = ', (i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))     \n",
    "    print('train time = ', trainTime)\n",
    "    \n",
    "gradientDescentStochastic(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = ', (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PART 2: Multi-layer Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we start to get further into Neural Networks, if you'd like to take time on your own for an in-depth introduction on the state of the art in the topic, check out this excellent 1-day tutorial from KDD2014:\n",
    "\n",
    "Part 1: http://videolectures.net/kdd2014_bengio_deep_learning/\n",
    "\n",
    "Part 2: http://videolectures.net/tcmm2014_taylor_deep_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "Let's take our implementation of logistic regression (which recall is in fact a single layer neural network), and add a hidden layer, making it a two layer neural network.  Because we have a hidden layer, we will now train the model using backpropagation.\n",
    "\n",
    "Exercise: How do you expect this model to compare to KNN and logistic regression in terms of train time and accuracy?  Why?\n",
    "\n",
    "Let's try it out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.3500\n",
      "2) accuracy = 0.6240\n",
      "3) accuracy = 0.8025\n",
      "4) accuracy = 0.8415\n",
      "5) accuracy = 0.8545\n",
      "6) accuracy = 0.8650\n",
      "7) accuracy = 0.8700\n",
      "8) accuracy = 0.8745\n",
      "9) accuracy = 0.8810\n",
      "10) accuracy = 0.8825\n",
      "11) accuracy = 0.8855\n",
      "12) accuracy = 0.8875\n",
      "13) accuracy = 0.8910\n",
      "14) accuracy = 0.8885\n",
      "15) accuracy = 0.8865\n",
      "16) accuracy = 0.8855\n",
      "17) accuracy = 0.8870\n",
      "18) accuracy = 0.8870\n",
      "19) accuracy = 0.8860\n",
      "20) accuracy = 0.8845\n",
      "21) accuracy = 0.8840\n",
      "22) accuracy = 0.8850\n",
      "23) accuracy = 0.8845\n",
      "24) accuracy = 0.8840\n",
      "25) accuracy = 0.8830\n",
      "26) accuracy = 0.8825\n",
      "27) accuracy = 0.8820\n",
      "28) accuracy = 0.8820\n",
      "29) accuracy = 0.8815\n",
      "30) accuracy = 0.8810\n",
      "31) accuracy = 0.8800\n",
      "32) accuracy = 0.8800\n",
      "33) accuracy = 0.8805\n",
      "34) accuracy = 0.8810\n",
      "35) accuracy = 0.8805\n",
      "36) accuracy = 0.8800\n",
      "37) accuracy = 0.8795\n",
      "38) accuracy = 0.8790\n",
      "39) accuracy = 0.8780\n",
      "40) accuracy = 0.8785\n",
      "41) accuracy = 0.8785\n",
      "42) accuracy = 0.8785\n",
      "43) accuracy = 0.8790\n",
      "44) accuracy = 0.8785\n",
      "45) accuracy = 0.8780\n",
      "46) accuracy = 0.8770\n",
      "47) accuracy = 0.8765\n",
      "48) accuracy = 0.8760\n",
      "49) accuracy = 0.8760\n",
      "50) accuracy = 0.8760\n",
      "train time = 635.35\n",
      "predict time = 0.02\n"
     ]
    }
   ],
   "source": [
    "## (1) Parameters\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "# Two notes:\n",
    "# First, feed forward is the composition of layers (dot product + activation function)\n",
    "# Second, activation on the hidden layer still uses sigmoid\n",
    "def model(X, w_1, w_2):\n",
    "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2))\n",
    "y_hat = model(X, w_1, w_2)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Change the number of nodes in the hidden layer?  What do you expect the impact to be?  What is the impact?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "As interest in networks with more layers and more complicated architechures has increased, a couple of tricks have emerged and become standard practice.  Let's look at two of those--rectifier activation and dropout noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:  We saw an improvement from adding a hidden layer.  What do you expect to happen if a second hidden layer was added?  \n",
    "\n",
    "Let's try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.1105\n",
      "2) accuracy = 0.1105\n",
      "3) accuracy = 0.1105\n",
      "4) accuracy = 0.0965\n",
      "5) accuracy = 0.0965\n",
      "6) accuracy = 0.0965\n",
      "7) accuracy = 0.1135\n",
      "8) accuracy = 0.1135\n",
      "9) accuracy = 0.1730\n",
      "10) accuracy = 0.2480\n",
      "train time = 52.73\n",
      "predict time = 0.04\n"
     ]
    }
   ],
   "source": [
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numHiddenNodes))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3]\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "def model(X, w_1, w_2, w_3):\n",
    "    return T.nnet.softmax(T.dot(T.nnet.sigmoid(T.dot(T.nnet.sigmoid(T.dot(X, w_1)), w_2)), w_3))\n",
    "y_hat = model(X, w_1, w_2, w_3)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Revisted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a recent idea around activation closely associated with deep learning.  In 2010, in a paper published at NIPS (https://www.utc.fr/~bordesan/dokuwiki/_media/en/glorot10nipsworkshop.pdf), Yoshua Bengio showed that rectifier activation works better empirically than sigmoid activation when used in the hidden layers.  \n",
    "\n",
    "The rectifier activation is simple: f(x)=max(0,x).  Intuitively, the difference is that as a sigmoid activated node approaches 1 it stops learning even if error continues to be propagated to it, whereas the rectifier activated node continue to learn (at least in the positive direction).  It is not completely understood (per Yoshua Bengio) why this helps, but there are some theories being explored including as related to the benefits of sparse representations in networks. (http://www.iro.umontreal.ca/~bengioy/talks/KDD2014-tutorial.pdf).  Rectifiers also speed up training.\n",
    "\n",
    "Although the paper was published in 2010, the technique didn't gain widespread adoption until 2012 when members of Hinton's group spread the word, including with this Kaggle entry: http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/\n",
    "\n",
    "Let's change the activation in our 2 layer network to rectifier and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.8260\n",
      "2) accuracy = 0.8665\n",
      "3) accuracy = 0.8760\n",
      "4) accuracy = 0.8915\n",
      "5) accuracy = 0.8945\n",
      "6) accuracy = 0.8975\n",
      "7) accuracy = 0.9015\n",
      "8) accuracy = 0.9020\n",
      "9) accuracy = 0.9030\n",
      "10) accuracy = 0.9040\n",
      "11) accuracy = 0.9065\n",
      "12) accuracy = 0.9070\n",
      "13) accuracy = 0.9075\n",
      "14) accuracy = 0.9065\n",
      "15) accuracy = 0.9075\n",
      "16) accuracy = 0.9080\n",
      "17) accuracy = 0.9080\n",
      "18) accuracy = 0.9105\n",
      "19) accuracy = 0.9105\n",
      "20) accuracy = 0.9110\n",
      "21) accuracy = 0.9120\n",
      "22) accuracy = 0.9115\n",
      "23) accuracy = 0.9120\n",
      "24) accuracy = 0.9115\n",
      "25) accuracy = 0.9120\n",
      "26) accuracy = 0.9120\n",
      "27) accuracy = 0.9120\n",
      "28) accuracy = 0.9110\n",
      "29) accuracy = 0.9115\n",
      "30) accuracy = 0.9120\n",
      "31) accuracy = 0.9125\n",
      "32) accuracy = 0.9125\n",
      "33) accuracy = 0.9130\n",
      "34) accuracy = 0.9130\n",
      "35) accuracy = 0.9130\n",
      "36) accuracy = 0.9130\n",
      "37) accuracy = 0.9125\n",
      "38) accuracy = 0.9120\n",
      "39) accuracy = 0.9120\n",
      "40) accuracy = 0.9120\n",
      "41) accuracy = 0.9115\n",
      "42) accuracy = 0.9120\n",
      "43) accuracy = 0.9125\n",
      "44) accuracy = 0.9125\n",
      "45) accuracy = 0.9135\n",
      "46) accuracy = 0.9135\n",
      "47) accuracy = 0.9135\n",
      "48) accuracy = 0.9135\n",
      "49) accuracy = 0.9135\n",
      "50) accuracy = 0.9135\n",
      "train time = 661.74\n",
      "predict time = 0.02\n"
     ]
    }
   ],
   "source": [
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "def model(X, w_1, w_2):\n",
    "    return T.nnet.softmax(T.dot(T.maximum(T.dot(X, w_1), 0.), w_2))\n",
    "y_hat = model(X, w_1, w_2)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1 \n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxout Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So rectifier activation worked great!  \n",
    "\n",
    "Exercise: try another type of activation called Maxout (or Max Pooling) activiation.  Maxout activation just selects the max input as the output.  Maxout is a type of pooling, a technique which performs particularly well for vision problems. For more background see: http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf and http://www.quora.com/What-is-impact-of-different-pooling-methods-in-convolutional-neural-networks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously when working with the MNIST data we saw a benefit in generalization from adding noise to the training data.  Let's try that again here, however this time with a trick for adding noise called 'Dropouts'.  The idea with dropouts is that instead of (or in addition to) adding noise to our inputs, we add noise by having each node return 0 with a certain probability during training.  This trick both improves generalization in large networks and speeds up training.\n",
    "\n",
    "Hinton introduced the idea in 2012 and gave an explanation of why it's similar to bagging (http://arxiv.org/pdf/1207.0580v1.pdf)\n",
    "\n",
    "Let's give it a try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.7735\n",
      "2) accuracy = 0.8600\n",
      "3) accuracy = 0.8620\n",
      "4) accuracy = 0.8810\n",
      "5) accuracy = 0.8960\n",
      "6) accuracy = 0.9020\n",
      "7) accuracy = 0.8925\n",
      "8) accuracy = 0.8980\n",
      "9) accuracy = 0.9185\n",
      "10) accuracy = 0.9175\n",
      "11) accuracy = 0.9180\n",
      "12) accuracy = 0.9160\n",
      "13) accuracy = 0.9125\n",
      "14) accuracy = 0.9215\n",
      "15) accuracy = 0.9265\n",
      "16) accuracy = 0.9245\n",
      "17) accuracy = 0.9275\n",
      "18) accuracy = 0.9215\n",
      "19) accuracy = 0.9280\n",
      "20) accuracy = 0.9300\n",
      "21) accuracy = 0.9280\n",
      "22) accuracy = 0.9205\n",
      "23) accuracy = 0.9260\n",
      "24) accuracy = 0.9235\n",
      "25) accuracy = 0.9350\n",
      "26) accuracy = 0.9315\n",
      "27) accuracy = 0.9295\n",
      "28) accuracy = 0.9340\n",
      "29) accuracy = 0.9280\n",
      "30) accuracy = 0.9295\n",
      "31) accuracy = 0.9275\n",
      "32) accuracy = 0.9340\n",
      "33) accuracy = 0.9315\n",
      "34) accuracy = 0.9275\n",
      "35) accuracy = 0.9315\n",
      "36) accuracy = 0.9295\n",
      "37) accuracy = 0.9315\n",
      "38) accuracy = 0.9305\n",
      "39) accuracy = 0.9310\n",
      "40) accuracy = 0.9305\n",
      "41) accuracy = 0.9310\n",
      "42) accuracy = 0.9290\n",
      "43) accuracy = 0.9270\n",
      "44) accuracy = 0.9305\n",
      "45) accuracy = 0.9310\n",
      "46) accuracy = 0.9290\n",
      "47) accuracy = 0.9310\n",
      "48) accuracy = 0.9285\n",
      "49) accuracy = 0.9315\n",
      "50) accuracy = 0.9360\n",
      "train time = 746.40\n",
      "predict time = 0.02\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "## (1) Parms\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "def model(X, w_1, w_2, p_1, p_2):\n",
    "    return T.nnet.softmax(T.dot(dropout(T.maximum(T.dot(dropout(X, p_1), w_1),0.), p_2), w_2))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, 0.2, 0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, 0., 0.)\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(50)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try once again adding a second hidden layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.5410\n",
      "2) accuracy = 0.7920\n",
      "3) accuracy = 0.8130\n",
      "4) accuracy = 0.8545\n",
      "5) accuracy = 0.8570\n",
      "6) accuracy = 0.8765\n",
      "7) accuracy = 0.8880\n",
      "8) accuracy = 0.9040\n",
      "9) accuracy = 0.8875\n",
      "10) accuracy = 0.9160\n",
      "train time = 58.12\n",
      "predict time = 0.03\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "\n",
    "## (1) Parmeters\n",
    "numHiddenNodes = 600 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(numFeatures, numHiddenNodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numHiddenNodes))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "def model(X, w_1, w_2, w_3, p_1, p_2, p_3):\n",
    "    return T.nnet.softmax(T.dot(dropout(T.maximum(T.dot(dropout(T.maximum(T.dot(dropout(X, p_1), w_1),0.), p_2), w_2),0.), p_3), w_3))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, w_3, 0.2, 0.5,0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, w_3, 0., 0.,0.)\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, when the phrase 'deep learning' is used to describe a system, it is often a convolution neural network (or convonet).  The convonet architechture was largely developed in the late 90's at Bell Labs, but only very recently popularized.  It was developed for image recognition, and is described and implemented with 2d representations in mind.\n",
    "\n",
    "Geoffrey Hinton has an excellent two-part lecture on the topic:\n",
    "\n",
    "https://www.youtube.com/watch?v=6oD3t6u5EPs\n",
    "\n",
    "https://www.youtube.com/watch?v=fueIAeAsGzA\n",
    "\n",
    "Also, this code was partly taken from these tutorials, which are worth referring back to:\n",
    "\n",
    "http://deeplearning.net/tutorial/lenet.html\n",
    "\n",
    "http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/\n",
    "\n",
    "https://www.youtube.com/watch?v=S75EdAcXHKk\n",
    "\n",
    "http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ysalomon/src/MIDS-W207/.env3/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ws == stride and pad == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "/Users/ysalomon/src/MIDS-W207/.env3/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ws == stride and pad == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "/Users/ysalomon/src/MIDS-W207/.env3/lib/python3.7/site-packages/ipykernel_launcher.py:43: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ws == stride and pad == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "/Users/ysalomon/src/MIDS-W207/.env3/lib/python3.7/site-packages/theano/tensor/basic.py:5281: UserWarning: flatten outdim parameter is deprecated, use ndim instead.\n",
      "  \"flatten outdim parameter is deprecated, use ndim instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accuracy = 0.7765\n",
      "2) accuracy = 0.9015\n",
      "3) accuracy = 0.9220\n",
      "4) accuracy = 0.9440\n",
      "5) accuracy = 0.9470\n",
      "6) accuracy = 0.9585\n",
      "7) accuracy = 0.9510\n",
      "8) accuracy = 0.9570\n",
      "9) accuracy = 0.9595\n",
      "10) accuracy = 0.9600\n",
      "train time = 3173.17\n",
      "predict time = 6.65\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.pool import pool_2d\n",
    "\n",
    "## (1) Parameters\n",
    "numHiddenNodes = 600 \n",
    "patchWidth = 3\n",
    "patchHeight = 3\n",
    "featureMapsLayer1 = 32\n",
    "featureMapsLayer2 = 64\n",
    "featureMapsLayer3 = 128\n",
    "\n",
    "# For convonets, we will work in 2d rather than 1d.  The MNIST images are 28x28 in 2d.\n",
    "imageWidth = 28\n",
    "train_data = train_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "test_data = test_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "\n",
    "# Convolution layers.  \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer1, 1, patchWidth, patchHeight))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer2, featureMapsLayer1, patchWidth, patchHeight))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3, featureMapsLayer2, patchWidth, patchHeight))*.01)))\n",
    "\n",
    "# Fully connected NN. \n",
    "w_4 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3 * 3 * 3, numHiddenNodes))*.01)))\n",
    "w_5 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3, w_4, w_5]\n",
    "\n",
    "## (2) Model\n",
    "X = T.tensor4() # conv2d works with tensor4 type\n",
    "Y = T.matrix()\n",
    "\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "# Theano provides built-in support for add convolutional layers\n",
    "def model(X, w_1, w_2, w_3, w_4, w_5, p_1, p_2):\n",
    "    l1 = dropout(pool_2d(T.maximum(conv2d(X, w_1, border_mode='full'),0.), (2, 2)), p_1)\n",
    "    l2 = dropout(pool_2d(T.maximum(conv2d(l1, w_2), 0.), (2, 2)), p_1)\n",
    "    l3 = dropout(T.flatten(pool_2d(T.maximum(conv2d(l2, w_3), 0.), (2, 2)), outdim=2), p_1) # flatten to switch back to 1d layers\n",
    "    l4 = dropout(T.maximum(T.dot(l3, w_4), 0.), p_2)\n",
    "    return T.nnet.softmax(T.dot(l4, w_5))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, w_3, w_4, w_5, 0.2, 0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, w_3, w_4, w_5, 0., 0.)\n",
    "y_x = T.argmax(y_hat, axis=1)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "## (4) Minimization.  \n",
    "def backprop(cost, w, alpha=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        \n",
    "        # adding gradient scaling\n",
    "        acc = theano.shared(w1.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * grad ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        grad = grad / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updates.append((w1, w1 - grad * alpha))\n",
    "    return updates\n",
    "\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_data), miniBatchSize), range(miniBatchSize, len(train_data), miniBatchSize)):\n",
    "            cost = train(train_data[start:end], train_labels_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print('%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(test_labels_b, axis=1) == predict(test_data))))\n",
    "    print('train time = %.2f' %(trainTime))\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(test_data)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional topic: Brain inspiration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architechture of the convonet was inspired by the visual cortext in the human brain.  If you are interested in learning more, check out: http://www-psych.stanford.edu/~ashas/Cognition%20Textbook/chapter2.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional topic: Self-Driving Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks are starting to be used more and more for self-driving vehicles.  This past year, NVIDEA started produced a chipset for self-driving vehicles that analyzes the video of up to 14 cameras using convonets for \n",
    "\n",
    "CES 2015 parts 6,7,9\n",
    "\n",
    "https://www.youtube.com/watch?v=-vKGkxeflGw\n",
    "\n",
    "https://www.youtube.com/watch?v=zsVsUvx8ieo\n",
    "\n",
    "https://www.youtube.com/watch?v=RvQVyGOynFY\n",
    "\n",
    "GTC 2015 parts 4,5,7,9\n",
    "\n",
    "https://www.youtube.com/watch?v=pqvdZ2jp1NA\n",
    "\n",
    "https://www.youtube.com/watch?v=GGxdP_JWhwI\n",
    "\n",
    "https://www.youtube.com/watch?v=Tb7ZYSTYHbw\n",
    "\n",
    "https://www.youtube.com/watch?v=TDm6Snkle70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
